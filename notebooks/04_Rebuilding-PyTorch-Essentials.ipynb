{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuilding PyTorch Essentials\n",
    "\n",
    "**Exploring and re-implementing the essential PyTorch internals for training neural networks**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Rebuilding-PyTorch-Essentials\" data-toc-modified-id=\"Rebuilding-PyTorch-Essentials-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Rebuilding PyTorch Essentials</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Pre-process-Data\" data-toc-modified-id=\"Pre-process-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Pre-process Data</a></span></li></ul></li><li><span><a href=\"#Bare-Training-Loop\" data-toc-modified-id=\"Bare-Training-Loop-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Bare Training Loop</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Build Model</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Train Model</a></span></li><li><span><a href=\"#Evaluate-Model\" data-toc-modified-id=\"Evaluate-Model-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Evaluate Model</a></span></li></ul></li><li><span><a href=\"#PyTorch-Data-Abstraction\" data-toc-modified-id=\"PyTorch-Data-Abstraction-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>PyTorch Data Abstraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Dataset</a></span></li><li><span><a href=\"#Dataloader\" data-toc-modified-id=\"Dataloader-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Dataloader</a></span></li><li><span><a href=\"#Random-Sampler\" data-toc-modified-id=\"Random-Sampler-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Random Sampler</a></span></li></ul></li><li><span><a href=\"#PyTorch-Training-Abstraction\" data-toc-modified-id=\"PyTorch-Training-Abstraction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>PyTorch Training Abstraction</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset.data.float(), dataset.targets\n",
    "x_train, x_test = x[:50000], x[50000:]\n",
    "y_train, y_test = y[:50000], y[50000:]\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc34bd868d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, mean, std): return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = x_train.mean()\n",
    "train_std = x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_test = normalize(x_test, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc34bc9f198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bare Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    \n",
    "    def __init__(self, x_dim, y_dim, h_dim):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(x_dim, h_dim),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(h_dim, y_dim)]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Config:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = (y_train.max() - y_train.min()+1).item()\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FC(m, c, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Config:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 1e-3\n",
    "bs = 128\n",
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    num_batches = (n-1)//bs\n",
    "    for i in range(num_batches):\n",
    "        # data minibatch\n",
    "        start_idx, end_idx = bs*i, bs*(i+1)\n",
    "        xb = x_train[start_idx:end_idx]\n",
    "        yb = y_train[start_idx:end_idx]\n",
    "        # forward pass \n",
    "        yb_pred = model(xb)\n",
    "        loss = loss_fn(yb_pred, yb)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update model\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= lr * layer.weight.grad\n",
    "                    layer.weight.grad.zero_()\n",
    "                if hasattr(layer, \"bias\"):\n",
    "                    layer.bias -= lr * layer.bias.grad\n",
    "                    layer.bias.grad.zero_()       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(input, target):\n",
    "    input_pred = torch.argmax(input, dim=-1)\n",
    "    return (input_pred==target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4383, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8857)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Data Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "**A simple wrapper for x's and y's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Loop using Dataset abstraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "test_ds = Dataset(x_train, y_test)x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    num_batches = (n-1)//bs\n",
    "    for i in range(num_batches):\n",
    "        # data minibatch\n",
    "        xb,yb = train_ds[bs*i:bs*(i+1)]\n",
    "        # forward pass \n",
    "        yb_pred = model(xb)\n",
    "        loss = loss_fn(yb_pred, yb)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update model\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= lr * layer.weight.grad\n",
    "                    layer.weight.grad.zero_()\n",
    "                if hasattr(layer, \"bias\"):\n",
    "                    layer.bias -= lr * layer.bias.grad\n",
    "                    layer.bias.grad.zero_()       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9040)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "**Loading minibatches from a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.ds, self.bs = dataset, batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(range(10))\n",
    "y = x*x\n",
    "dummy_ds = Dataset(x,y)\n",
    "dummy_dl = DataLoader(dummy_ds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0., 1.]), tensor([0., 1.])),\n",
       " (tensor([2., 3.]), tensor([4., 9.])),\n",
       " (tensor([4., 5.]), tensor([16., 25.])),\n",
       " (tensor([6., 7.]), tensor([36., 49.])),\n",
       " (tensor([8., 9.]), tensor([64., 81.]))]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(xb,yb) for xb,yb in dummy_dl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Loop using DataLoader abstraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "test_ds = Dataset(x_train, y_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, bs)\n",
    "test_dl = DataLoader(test_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # data minibatch\n",
    "    for xb,yb in train_dl:\n",
    "        # forward pass \n",
    "        yb_pred = model(xb)\n",
    "        loss = loss_fn(yb_pred, yb)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update model\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= lr * layer.weight.grad\n",
    "                    layer.weight.grad.zero_()\n",
    "                if hasattr(layer, \"bias\"):\n",
    "                    layer.bias -= lr * layer.bias.grad\n",
    "                    layer.bias.grad.zero_()       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9143)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampler\n",
    "**Shuffles data during batch training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    \n",
    "    def __init__(self, data_size, batch_size, shuffle):\n",
    "        self.n, self.bs, self.shuffle = data_size, batch_size, shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        sample_idx = torch.randperm(self.n) if self.shuffle else list(range(self.n))\n",
    "        for i in range(0, self.n, self.bs):\n",
    "            yield sample_idx[i : i+self.bs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(range(10))\n",
    "y = x*x\n",
    "dummy_samp = Sampler(10, 2, False)\n",
    "print([samples for samples in dummy_samp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 4]), tensor([7, 2]), tensor([3, 5]), tensor([6, 0]), tensor([8, 9])]\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(range(10))\n",
    "y = x*x\n",
    "dummy_samp = Sampler(10, 2, True)\n",
    "print([samples for samples in dummy_samp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataLoader with shuffling feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, sampler, collate_fn):\n",
    "        self.ds, self.bs = dataset, batch_size        \n",
    "        self.sampler, self.collate_fn = sampler, collate_fn\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch_idxs in self.sampler:\n",
    "            yield self.collate_fn([self.ds[idx] for idx in batch_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0., 1.]), tensor([0., 1.])),\n",
       " (tensor([2., 3.]), tensor([4., 9.])),\n",
       " (tensor([4., 5.]), tensor([16., 25.])),\n",
       " (tensor([6., 7.]), tensor([36., 49.])),\n",
       " (tensor([8., 9.]), tensor([64., 81.]))]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(range(10))\n",
    "y = x*x\n",
    "\n",
    "dummy_ds =  Dataset(x, y)\n",
    "dummy_samp = Sampler(10, 2, False)\n",
    "dummy_dl = DataLoader(dummy_ds, bs, dummy_samp, collate)\n",
    "\n",
    "[batch for batch in dummy_dl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([5., 3.]), tensor([25.,  9.])),\n",
       " (tensor([7., 8.]), tensor([49., 64.])),\n",
       " (tensor([1., 2.]), tensor([1., 4.])),\n",
       " (tensor([9., 6.]), tensor([81., 36.])),\n",
       " (tensor([4., 0.]), tensor([16.,  0.]))]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(range(10))\n",
    "y = x*x\n",
    "\n",
    "dummy_ds =  Dataset(x, y)\n",
    "dummy_samp = Sampler(10, 2, True)\n",
    "dummy_dl = DataLoader(dummy_ds, bs, dummy_samp, collate)\n",
    "\n",
    "[batch for batch in dummy_dl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Loop with shuffled DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(x_train, y_train)\n",
    "test_ds = Dataset(x_train, y_test)\n",
    "\n",
    "train_samp = Sampler(len(train_ds), bs, shuffle=True)\n",
    "test_samp = Sampler(len(test_ds), bs, shuffle=False)\n",
    "\n",
    "train_dl = DataLoader(train_ds, bs, train_samp, collate)\n",
    "test_dl = DataLoader(test_ds, bs, test_samp, collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # data minibatch\n",
    "    for xb,yb in train_dl:\n",
    "        # forward pass \n",
    "        yb_pred = model(xb)\n",
    "        loss = loss_fn(yb_pred, yb)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # update model\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer, \"weight\"):\n",
    "                    layer.weight -= lr * layer.weight.grad\n",
    "                    layer.weight.grad.zero_()\n",
    "                if hasattr(layer, \"bias\"):\n",
    "                    layer.bias -= lr * layer.bias.grad\n",
    "                    layer.bias.grad.zero_()       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9220)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Training Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prod] *",
   "language": "python",
   "name": "conda-env-prod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
