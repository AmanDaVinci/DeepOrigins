{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Forward Pass\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset.data.float(), dataset.targets\n",
    "x_train, x_test = x[:50000], x[50000:]\n",
    "y_train, y_test = y[:50000], y[50000:]\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae4a814748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = (y_train.max() - y_train.min()).item()\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a, b, compare, compare_name=None):\n",
    "    if compare_name is None:\n",
    "        compare_name = compare.__name__\n",
    "    assert compare(a, b),\\\n",
    "    f\"{compare_name} check failed:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_zero(x, tol=1e-3):\n",
    "    test(x, tol, operator.le, f\"Zero (less than tolerance: {tol})\")\n",
    "    \n",
    "def test_equality(a, b):\n",
    "    test(a, b, operator.eq, \"Equality\")\n",
    "\n",
    "def test_approximately(a, b):\n",
    "    allclose = partial(torch.allclose, atol=1e-5, rtol=1e-03)\n",
    "    if not isinstance(a, torch.Tensor) or not isinstance(b, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "        b = torch.tensor(b)\n",
    "    test(a, b, allclose, \"Approximate Equality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, mean, std): return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = x_train.mean()\n",
    "train_std = x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_test = normalize(x_test, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fae4a73c390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is it difficult to train feedforward neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the difficulty of training deep feedforward neural networks - Glorot, X. & Bengio, Y. (2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Exploding Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing linear layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh1 = m//2\n",
    "w1 = torch.randn(m, nh1)\n",
    "b1 = torch.zeros(nh1)\n",
    "\n",
    "nh2 = nh1//2 \n",
    "w2 = torch.randn(nh1, nh2)\n",
    "b2 = torch.zeros(nh2)\n",
    "\n",
    "nh3 = nh2//2\n",
    "w3 = torch.randn(nh2, nh3)\n",
    "b3 = torch.zeros(nh3)\n",
    "\n",
    "nh4 = nh3//2\n",
    "w4 = torch.randn(nh3, nh4)\n",
    "b4 = torch.zeros(nh4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.), torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2964), tensor(27.9827), torch.Size([50000, 392]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = x_train@w1 + b1\n",
    "h1.mean(), h1.std(), h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.9289), tensor(537.8209), torch.Size([50000, 196]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = h1@w2 + b2\n",
    "h2.mean(), h2.std(), h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(112.1643), tensor(7692.3428), torch.Size([50000, 98]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3 = h2@w3 + b3\n",
    "h3.mean(), h3.std(), h3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9801.2500), tensor(75005.3047), torch.Size([50000, 49]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = h3@w4 + b4\n",
    "h4.mean(), h4.std(), h4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe exploding activations as their standard deviations and mean increase drastically at every layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Xavier Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing linear layers with Xaiver Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh1 = m//2\n",
    "w1 = torch.randn(m, nh1) / math.sqrt(m)\n",
    "b1 = torch.zeros(nh1)\n",
    "\n",
    "nh2 = nh1//2 \n",
    "w2 = torch.randn(nh1, nh2) / math.sqrt(nh1) \n",
    "b2 = torch.zeros(nh2)\n",
    "\n",
    "nh3 = nh2//2\n",
    "w3 = torch.randn(nh2, nh3) / math.sqrt(nh2)\n",
    "b3 = torch.zeros(nh3)\n",
    "\n",
    "nh4 = nh3//2\n",
    "w4 = torch.randn(nh3, nh4) / math.sqrt(nh1)\n",
    "b4 = torch.zeros(nh4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.), torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0436), tensor(1.0104), torch.Size([50000, 392]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = x_train@w1 + b1\n",
    "h1.mean(), h1.std(), h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0174), tensor(1.0042), torch.Size([50000, 196]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = h1@w2 + b2\n",
    "h2.mean(), h2.std(), h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0114), tensor(1.0135), torch.Size([50000, 98]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3 = h2@w3 + b3\n",
    "h3.mean(), h3.std(), h3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0132), tensor(0.5071), torch.Size([50000, 49]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = h3@w4 + b4\n",
    "h4.mean(), h4.std(), h4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean & std of activations remain fairly close to 0 and 1 respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Vanishing Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear layers with Relu activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x): return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_relu(x, weight, bias): return relu(x@weight + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.), torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4202), tensor(0.6041), torch.Size([50000, 392]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = linear_relu(x_train, w1, b1)\n",
    "h1.mean(), h1.std(), h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3120), tensor(0.4489), torch.Size([50000, 196]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = linear_relu(h1, w2, b2)\n",
    "h2.mean(), h2.std(), h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2009), tensor(0.3210), torch.Size([50000, 98]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3 = linear_relu(h2, w3, b3)\n",
    "h3.mean(), h3.std(), h3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0722), tensor(0.1102), torch.Size([50000, 49]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = linear_relu(h3, w4, b4)\n",
    "h4.mean(), h4.std(), h4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe the activations vanishing as their standard deviation reduces by half at every layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution: Kaiming Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing linear layers with Kaiming Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh1 = m//2\n",
    "w1 = torch.randn(m, nh1) * math.sqrt(2/m)\n",
    "b1 = torch.zeros(nh1)\n",
    "\n",
    "nh2 = nh1//2 \n",
    "w2 = torch.randn(nh1, nh2) * math.sqrt(2/nh1) \n",
    "b2 = torch.zeros(nh2)\n",
    "\n",
    "nh3 = nh2//2\n",
    "w3 = torch.randn(nh2, nh3) * math.sqrt(2/nh2)\n",
    "b3 = torch.zeros(nh3)\n",
    "\n",
    "nh4 = nh3//2\n",
    "w4 = torch.randn(nh3, nh4) * math.sqrt(2/nh1)\n",
    "b4 = torch.zeros(nh4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.), torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5175), tensor(0.7877), torch.Size([50000, 392]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = linear_relu(x_train, w1, b1)\n",
    "h1.mean(), h1.std(), h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5050), tensor(0.7644), torch.Size([50000, 196]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = linear_relu(h1, w2, b2)\n",
    "h2.mean(), h2.std(), h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5289), tensor(0.7422), torch.Size([50000, 98]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3 = linear_relu(h2, w3, b3)\n",
    "h3.mean(), h3.std(), h3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2165), tensor(0.3361), torch.Size([50000, 49]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = linear_relu(h3, w4, b4)\n",
    "h4.mean(), h4.std(), h4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe the standard deviation of activations behaving much better with Kaiming initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, the mean of the activations hover around 0.5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifted Relu: Better Solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear layers with shifted Relu activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_relu(x): return x.clamp_min(0.) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_shift_relu(x, weight, bias): return shift_relu(x@weight + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06), tensor(1.), torch.Size([50000, 784]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0175), tensor(0.7877), torch.Size([50000, 392]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = linear_shift_relu(x_train, w1, b1)\n",
    "h1.mean(), h1.std(), h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0701), tensor(0.6528), torch.Size([50000, 196]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2 = linear_shift_relu(h1, w2, b2)\n",
    "h2.mean(), h2.std(), h2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.1287), tensor(0.5455), torch.Size([50000, 98]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3 = linear_shift_relu(h2, w3, b3)\n",
    "h3.mean(), h3.std(), h3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.3418), tensor(0.2343), torch.Size([50000, 49]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = linear_shift_relu(h3, w4, b4)\n",
    "h4.mean(), h4.std(), h4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean of activations remain close to zero at every layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    '''Affine layer with weight and bias initialized using Kaiming initialization'''\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = torch.randn(in_size, out_size) * math.sqrt(2/in_size)\n",
    "        self.bias = torch.zeros(out_size)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(Linear: in={self.weight.shape[0]} out={self.weight.shape[1]})\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x@self.weight + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    '''Rectified Linear Unit Layer'''\n",
    "    \n",
    "    def __init__(self, shift=0.):\n",
    "        self.shift = shift\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(ReLU: shift={self.shift})\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.clamp_min(0.) - self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN():\n",
    "    '''Feedforward neural network'''\n",
    "    \n",
    "    def __init__(self, x_size, y_size, num_layers):\n",
    "        downsize = (x_size-y_size)//num_layers\n",
    "        in_size = x_size\n",
    "        out_size = x_size-downsize\n",
    "        self.layers = [Linear(in_size, out_size), ReLU()]\n",
    "        for i in range(num_layers-2):\n",
    "            in_size = out_size \n",
    "            out_size = in_size - downsize\n",
    "            self.layers.append(Linear(in_size, out_size))\n",
    "            self.layers.append(ReLU())\n",
    "        in_size = out_size\n",
    "        out_size = y_size\n",
    "        self.layers.append(Linear(in_size, out_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedForwardNN(784, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Linear: in=784 out=630),\n",
       " (ReLU: shift=0.0),\n",
       " (Linear: in=630 out=476),\n",
       " (ReLU: shift=0.0),\n",
       " (Linear: in=476 out=322),\n",
       " (ReLU: shift=0.0),\n",
       " (Linear: in=322 out=168),\n",
       " (ReLU: shift=0.0),\n",
       " (Linear: in=168 out=10)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.forward(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 10]), torch.Size([50000]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred, y_true): return (y_pred - y_true).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedForwardNN(784, 1, 5)\n",
    "y_pred = model.forward(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34.7165)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_pred.squeeze(-1), y_train.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_scalar(y_hat, y):\n",
    "    if y==1:\n",
    "        return -y_hat.log()\n",
    "    elif y==0.:\n",
    "        return -(1-y_hat).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return -(y*y_hat.log() + (1-y)*(1-y_hat).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedForwardNN(784, 10, 5)\n",
    "y_pred = model.forward(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   nan,    nan, 0.1064,  ...,    nan,    nan, 2.2289],\n",
       "        [1.9161,    nan,    nan,  ...,    nan,    nan, 2.1351],\n",
       "        [   nan,    nan,    nan,  ...,    nan, 0.2495, 0.8286],\n",
       "        ...,\n",
       "        [   nan,    nan, 0.2143,  ...,    nan, 0.2518,    nan],\n",
       "        [   nan, 1.5226,    nan,  ...,    nan,    nan,    nan],\n",
       "        [   nan,    nan,    nan,  ..., 0.1055,    nan,    nan]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = torch.nn.functional.one_hot(y_train)\n",
    "cross_entropy(y_pred, y_one_hot.float())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prod] *",
   "language": "python",
   "name": "conda-env-prod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
