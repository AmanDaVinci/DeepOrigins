{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagating Gradients Backwards\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Propagating-Gradients-Backwards\" data-toc-modified-id=\"Propagating-Gradients-Backwards-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Propagating Gradients Backwards</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Unit-Tests\" data-toc-modified-id=\"Unit-Tests-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Unit Tests</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Normalize-Data\" data-toc-modified-id=\"Normalize-Data-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Normalize Data</a></span></li></ul></li><li><span><a href=\"#Backpropagation-from-scratch\" data-toc-modified-id=\"Backpropagation-from-scratch-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Backpropagation from scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-Layer\" data-toc-modified-id=\"Linear-Layer-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Linear Layer</a></span></li><li><span><a href=\"#Activation-Layer\" data-toc-modified-id=\"Activation-Layer-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Activation Layer</a></span></li><li><span><a href=\"#Loss-Layer\" data-toc-modified-id=\"Loss-Layer-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Loss Layer</a></span></li><li><span><a href=\"#Feedforward-Network\" data-toc-modified-id=\"Feedforward-Network-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Feedforward Network</a></span></li></ul></li><li><span><a href=\"#Refactor-&amp;-Redesign\" data-toc-modified-id=\"Refactor-&amp;-Redesign-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Refactor &amp; Redesign</a></span><ul class=\"toc-item\"><li><span><a href=\"#Abstract-Layer-Class\" data-toc-modified-id=\"Abstract-Layer-Class-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Abstract Layer Class</a></span></li><li><span><a href=\"#Linear-Layer\" data-toc-modified-id=\"Linear-Layer-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Linear Layer</a></span></li><li><span><a href=\"#Activation-Layer\" data-toc-modified-id=\"Activation-Layer-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Activation Layer</a></span></li><li><span><a href=\"#Loss-Layer\" data-toc-modified-id=\"Loss-Layer-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Loss Layer</a></span></li><li><span><a href=\"#Feedforward-Network\" data-toc-modified-id=\"Feedforward-Network-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Feedforward Network</a></span></li></ul></li><li><span><a href=\"#Comparison-with-PyTorch's-Autograd\" data-toc-modified-id=\"Comparison-with-PyTorch's-Autograd-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Comparison with PyTorch's Autograd</a></span><ul class=\"toc-item\"><li><span><a href=\"#PyTorch's-Performance\" data-toc-modified-id=\"PyTorch's-Performance-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>PyTorch's Performance</a></span></li><li><span><a href=\"#Our-Model's-Performance\" data-toc-modified-id=\"Our-Model's-Performance-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Our Model's Performance</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a, b, compare, compare_name=None):\n",
    "    if compare_name is None:\n",
    "        compare_name = compare.__name__\n",
    "    assert compare(a, b),\\\n",
    "    f\"{compare_name} check failed:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_zero(x, tol=1e-3):\n",
    "    test(x, tol, operator.le, f\"Zero (less than tolerance: {tol})\")\n",
    "    \n",
    "def test_equality(a, b):\n",
    "    test(a, b, operator.eq, \"Equality\")\n",
    "\n",
    "def test_approximately(a, b):\n",
    "    allclose = partial(torch.allclose, atol=1e-5, rtol=1e-03)\n",
    "    if not isinstance(a, torch.Tensor) or not isinstance(b, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "        b = torch.tensor(b)\n",
    "    test(a, b, allclose, \"Approximate Equality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset.data.float(), dataset.targets\n",
    "x_train, x_test = x[:50000], x[50000:]\n",
    "y_train, y_test = y[:50000], y[50000:]\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0556adb10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = (y_train.max() - y_train.min()).item()\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, mean, std): return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = x_train.mean()\n",
    "train_std = x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_test = normalize(x_test, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0555b1390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    '''Affine layer with weight and bias initialized using Kaiming initialization'''\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = torch.randn(in_size, out_size) * math.sqrt(2/in_size)\n",
    "        self.bias = torch.zeros(out_size)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(Linear: in={self.weight.shape[0]} out={self.weight.shape[1]})\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = self.x@self.weight + self.bias \n",
    "        return self.y\n",
    "    \n",
    "    def backward(self):\n",
    "        self.weight.g = self.x.t() @ self.y.g \n",
    "        self.bias.g = self.y.g\n",
    "        self.x.g = self.y.g @ self.weight.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    '''Rectified Linear Unit Layer'''\n",
    "    \n",
    "    def __init__(self, shift=0.):\n",
    "        self.shift = shift\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(ReLU: shift={self.shift})\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.y = self.x.clamp_min(0.) - self.shift \n",
    "        return self.y\n",
    "    \n",
    "    def backward(self):\n",
    "        self.x.g = self.y.g * (self.x>0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE():\n",
    "    '''Mean Squared Error Layer'''\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Loss: Mean Squared Error\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.x1 = y_pred\n",
    "        self.x2 = y_true\n",
    "        self.y = (self.x1-self.x2).pow(2).mean() \n",
    "        return self.y\n",
    "    \n",
    "    def backward(self):\n",
    "        self.x1.g = 2 * (self.x1-self.x2) / self.x1.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN():\n",
    "    '''Feedforward neural network'''\n",
    "\n",
    "    def __init__(self, x_dim, y_dim, n_layers):\n",
    "        # get an exponentially spaced array of layer dimensions\n",
    "        def _exp(pos): return math.ceil(x_dim * (y_dim/x_dim)**pos)\n",
    "        layer_dims  = [_exp(pos/n_layers) for pos in range(0, n_layers+1)]\n",
    "        # construct the list of layers\n",
    "        self.layers = []\n",
    "        for i in range(n_layers):\n",
    "            in_dim, out_dim = layer_dims[i], layer_dims[i+1]\n",
    "            self.layers.append(Linear(in_dim, out_dim))\n",
    "            self.layers.append(ReLU())\n",
    "        self.loss = MSE()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        model_str = \"\\n\".join(l.__repr__() for l in self.layers)\n",
    "        model_str += \"\\n\" + self.loss.__repr__()\n",
    "        return model_str\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear: in=784 out=207)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=207 out=55)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=55 out=15)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=15 out=4)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=4 out=1)\n",
       "(ReLU: shift=0.0)\n",
       "Loss: Mean Squared Error"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedForwardNN(x_dim=784, y_dim=1, n_layers=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.forward(x_train)\n",
    "loss = model.loss.forward(y_pred.float(), y_train.unsqueeze(-1).float())\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor & Redesign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    '''Abstract Layer class like PyTorch's nn.Module'''\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.y = self.forward(*self.args)\n",
    "        return self.y\n",
    "\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError(\"__repr__ method not implemented\")\n",
    "\n",
    "    def forward(self, *args):\n",
    "        raise NotImplementedError(\"forward method not implemented\")\n",
    "        \n",
    "    def backward(self):\n",
    "        raise NotImplementedError(\"backward method not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    '''Affine layer with weight and bias initialized using Kaiming initialization'''\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.weight = torch.randn(in_size, out_size) * math.sqrt(2/in_size)\n",
    "        self.bias = torch.zeros(out_size)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(Linear: in={self.weight.shape[0]} out={self.weight.shape[1]})\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x@self.weight + self.bias \n",
    "    \n",
    "    def backward(self):\n",
    "        self.weight.g = self.args[0].t() @ self.y.g \n",
    "        self.bias.g = self.y.g\n",
    "        self.args[0].g = self.y.g @ self.weight.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    '''Rectified Linear Unit Layer'''\n",
    "    \n",
    "    def __init__(self, shift=0.):\n",
    "        self.shift = shift\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"(ReLU: shift={self.shift})\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.clamp_min(0.) - self.shift\n",
    "    \n",
    "    def backward(self):\n",
    "        self.args[0].g = self.y.g * (self.args[0]>0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Layer):\n",
    "    '''Mean Squared Error Layer'''\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Loss: Mean Squared Error\"\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        return (y_pred-y_true).pow(2).mean()\n",
    "    \n",
    "    def backward(self):\n",
    "        n = self.args[0].shape[0]\n",
    "        self.args[0].g = 2 * (self.args[0] - self.args[1]) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(Layer):\n",
    "    '''Feedforward neural network'''\n",
    "\n",
    "    def __init__(self, x_dim, y_dim, n_layers):\n",
    "        # get an exponentially spaced array of layer dimensions\n",
    "        def _exp(pos): return math.ceil(x_dim * (y_dim/x_dim)**pos)\n",
    "        layer_dims  = [_exp(pos/n_layers) for pos in range(0, n_layers+1)]\n",
    "        # construct the list of layers\n",
    "        self.layers = []\n",
    "        for i in range(n_layers):\n",
    "            in_dim, out_dim = layer_dims[i], layer_dims[i+1]\n",
    "            self.layers.append(Linear(in_dim, out_dim))\n",
    "            self.layers.append(ReLU())\n",
    "        self.loss = MSE()\n",
    "            \n",
    "    def __repr__(self):\n",
    "        model_str = \"\\n\".join(l.__repr__() for l in self.layers)\n",
    "        model_str += \"\\n\" + self.loss.__repr__()\n",
    "        return model_str\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear: in=784 out=207)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=207 out=55)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=55 out=15)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=15 out=4)\n",
       "(ReLU: shift=0.0)\n",
       "(Linear: in=4 out=1)\n",
       "(ReLU: shift=0.0)\n",
       "Loss: Mean Squared Error"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeedForwardNN(x_dim=784, y_dim=1, n_layers=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_train)\n",
    "loss = model.loss(y_pred.float(), y_train.unsqueeze(-1).float())\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with PyTorch's Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from functools import partial\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f346405e8f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, x_dim, h_dim, y_dim):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(x_dim, h_dim),\n",
    "                       nn.ReLU(),\n",
    "                       nn.Linear(h_dim,y_dim)]\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchModel(784, 400, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_forward = timeit.timeit(partial(torch_model,x_train), number=10)\n",
    "y_pred = torch_model(x_train)\n",
    "loss = torch_model.loss(y_pred, y_train.unsqueeze(-1).float())\n",
    "torch_backward = timeit.timeit(loss.backward, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3273273869999684, 0.23294704500040098)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_forward, torch_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModel(Layer):\n",
    "    \n",
    "    def __init__(self, x_dim, h_dim, y_dim):\n",
    "        self.layers = [Linear(x_dim, h_dim),\n",
    "                       ReLU(),\n",
    "                       Linear(h_dim, y_dim)]\n",
    "        self.loss = MSE()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OurModel(784, 400, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = timeit.timeit(partial(model,x_train), number=10)\n",
    "y_pred = model(x_train)\n",
    "loss = model.loss(y_pred, y_train.unsqueeze(-1).float())\n",
    "backward = timeit.timeit(model.backward, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7871809229991413, 0.2806604300003528)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward, backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "* [ ] Write a reproducible test for correctness of gradient calculation    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prod] *",
   "language": "python",
   "name": "conda-env-prod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
