{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize Training with Callbacks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epochs': 20,\n",
    "    'lr': 0.1,\n",
    "    'bs': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = utils.get_data()\n",
    "train_dl, test_dl = utils.get_dataloaders(x_train, y_train, x_test, y_test, config['bs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.Databunch(train_dl, test_dl, n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 300), nn.ReLU(), nn.Linear(300,100), nn.ReLU(), nn.Linear(100,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr = config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = utils.Learner(model, data, optim, F.cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Callback System\n",
    "---\n",
    "**WARNING: Bad Smelly Code Ahead!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Callback Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    \"\"\"\n",
    "    Abstract class inherited by all callbacks\n",
    "  \n",
    "    All methods return true by default\n",
    "    to avoid interrupting the training loop    \n",
    "    \"\"\"\n",
    "    \n",
    "    def before_train(self, learner):\n",
    "        self.learner = learner\n",
    "        return True\n",
    "    \n",
    "    def before_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "        return True\n",
    "    \n",
    "    def before_batch(self, xb, yb):\n",
    "        self.xb, self.yb = xb, yb\n",
    "        return True\n",
    "    \n",
    "    def after_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        return True\n",
    "    \n",
    "    def after_backward(self):  return True\n",
    "    def after_step(self):      return True\n",
    "    def before_validate(self): return True\n",
    "    def after_epoch(self):     return True\n",
    "    def after_train(self):     return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(Callback):\n",
    "    '''Test callback system to stop training at given iteration'''\n",
    "    \n",
    "    def __init__(self, stop_train_at=10):\n",
    "        self.stop_at = stop_train_at\n",
    "        \n",
    "    def before_train(self, learner):\n",
    "        super().before_train(learner)\n",
    "        self.iters = 0\n",
    "        return True\n",
    "    \n",
    "    def after_step(self):\n",
    "        self.iters += 1\n",
    "        print(self.iters)\n",
    "        if self.iters > self.stop_at:\n",
    "            self.learner.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackController:\n",
    "    '''Runs the registered callbacks during a training loop'''\n",
    "    \n",
    "    def __init__(self, callbacks):\n",
    "        self.cbs = callbacks if callbacks else []\n",
    "    \n",
    "    def before_train(self, learner):\n",
    "        self.learner = learner\n",
    "        self.in_train = True\n",
    "        carry_on = True\n",
    "        self.learner.stop = False\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.before_train(model)\n",
    "        return carry_on\n",
    "    \n",
    "    def after_train(self):\n",
    "        carry_on = not self.in_train\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.after_train()\n",
    "        return carry_on\n",
    "    \n",
    "    def before_epoch(self, epoch):\n",
    "        self.learner.model.train()\n",
    "        self.in_train = True\n",
    "        carry_on = True\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.before_epoch(epoch)\n",
    "        return carry_on\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        carry_on = True\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.after_epoch()\n",
    "        return carry_on\n",
    "    \n",
    "    def before_batch(self, xb, yb):\n",
    "        carry_on = True\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.before_batch(xb, yb)\n",
    "        return carry_on\n",
    "        \n",
    "    def before_validate(self):\n",
    "        self.learner.model.eval()\n",
    "        self.in_train = False\n",
    "        carry_on = True\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.before_validate()\n",
    "        return carry_on\n",
    "        \n",
    "    def after_loss(self, loss):\n",
    "        carry_on = self.in_train\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.after_loss(loss)\n",
    "        return carry_on\n",
    "    \n",
    "    def after_backward(self):\n",
    "        carry_on = True\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.after_backward()\n",
    "        return carry_on\n",
    "    \n",
    "    def after_step(self):\n",
    "        carry_on = True\n",
    "        for cb in self.cbs:\n",
    "            carry_on = carry_on and cb.after_step()\n",
    "        return carry_on\n",
    "    \n",
    "    def do_stop(self):\n",
    "        try:     return self.learner.stop\n",
    "        finally: self.learner.stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(xb, yb, cb):\n",
    "    if not cb.before_batch(xb, yb): return\n",
    "    yb_pred = cb.learner.model(xb)\n",
    "    loss = cb.learner.loss_func(yb_pred, yb)\n",
    "    if not cb.after_loss(loss): return\n",
    "    loss.backward()\n",
    "    if cb.after_backward(): cb.learner.opt.step()\n",
    "    if cb.after_step(): cb.learner.opt.zero_grad()\n",
    "\n",
    "def train_all_batches(dl, cb):\n",
    "    for xb,yb in dl:\n",
    "        train_one_batch(xb, yb, cb)\n",
    "        if cb.do_stop: return\n",
    "    \n",
    "def train(epochs, learner, cb):\n",
    "    if not cb.before_train(learner): return\n",
    "    for epoch in range(epochs):\n",
    "        if not cb.before_epoch(epoch): continue\n",
    "        train_all_batches(learner.data.train_dl, cb)\n",
    "        \n",
    "        if cb.before_validate():\n",
    "            with torch.no_grad():\n",
    "                train_all_batches(learner.data.test_dl, cb)\n",
    "        if cb.do_stop() or not cb.after_epoch(): return\n",
    "    cb.after_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Doesn't work. Fix it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "train(config['epochs'], learner,\n",
    "      CallbackController([Test(stop_train_at=10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Callback System\n",
    "---\n",
    "**Cleaning up the mess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Callback Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel2snake(name):\n",
    "    _camel_r1 = \"(.)([A-Z][a-z]+)\"\n",
    "    _camel_r2 = \"([a-z0-9])([A-Z])\"\n",
    "    s1 = re.sub(_camel_r1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_r2, r'\\1_\\2', s1).lower()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    '''Abstract Callback Class'''\n",
    "    _order = 0\n",
    "    \n",
    "    def set_controller(self, control):  self.control = control\n",
    "    def __getattr__(self, attr):        return getattr(self.control, attr)\n",
    "    @property\n",
    "    def name(self):                     return camel2snake(name or 'callback')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller:\n",
    "    '''Main Controller responsible for callbacks and training loop'''\n",
    "    \n",
    "    def __init__(self, callback_list=[]):\n",
    "        self.cbs = [TrainEval()] + callback_list\n",
    "        self.stop = False\n",
    "    \n",
    "    @property\n",
    "    def model(self):     return self.learner.model\n",
    "    @property\n",
    "    def data(self):      return self.learner.data\n",
    "    @property\n",
    "    def opt(self):       return self.learner.opt\n",
    "    @property\n",
    "    def loss_func(self): return self.learner.loss_func\n",
    "\n",
    "    def run_one_batch(self, xb, yb):\n",
    "        self.xb, self.yb = xb, yb\n",
    "        if self('before_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if self('after_pred'): return\n",
    "        self.loss = self.loss_func(self.pred, self.yb)\n",
    "        if self('after_loss') or not self.in_train: return\n",
    "        self.loss.backward()\n",
    "        if self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "        self('after_batch')\n",
    "        \n",
    "    def run_all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb, yb in dl:\n",
    "            if self.stop: break\n",
    "            self.run_one_batch(xb, yb)\n",
    "        self.stop = False\n",
    "    \n",
    "    def train(self, learner, epochs):\n",
    "        self.learner, self.epochs = learner, epochs\n",
    "        try:\n",
    "            for cb in self.cbs: \n",
    "                cb.set_controller(self)\n",
    "            if self('before_train'): return\n",
    "            for epoch in range(self.epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('before_epoch'):\n",
    "                    self.run_all_batches(self.data.train_dl)\n",
    "                with torch.no_grad():\n",
    "                    if not self('before_validate'):\n",
    "                        self.run_all_batches(self.data.test_dl)\n",
    "                if self('after_epoch'): break\n",
    "        finally:\n",
    "            self('after_train')\n",
    "    \n",
    "    def __call__(self, cb_func_name):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            # get the callback function if defined or else None \n",
    "            cb_func = getattr(cb, cb_func_name, None)\n",
    "            # run only if cb_func is not None\n",
    "            if cb_func and cb_func(): return True\n",
    "        # when a callback function was not defined in any of the callbacks\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback: Train Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEval(Callback):\n",
    "    \"\"\"\n",
    "    Callback to switch between train and eval mode,\n",
    "    as well as keep track of iterations during training.\n",
    "    \n",
    "    Note: This callback is attached by default\n",
    "    \"\"\"\n",
    "    \n",
    "    def before_train(self):\n",
    "        self.control.n_epochs = 0.\n",
    "        self.control.n_iter = 0.\n",
    "    \n",
    "    def before_epoch(self):\n",
    "        self.control.model.train()\n",
    "        self.control.in_train = True\n",
    "        self.control.n_epochs = self.control.epoch\n",
    "    \n",
    "    def before_batch(self):\n",
    "        if not self.control.in_train: return\n",
    "        self.control.n_epochs += 1./self.control.iters\n",
    "        self.control.n_iter += 1\n",
    "    \n",
    "    def before_validate(self):\n",
    "        self.control.model.eval()\n",
    "        self.control.in_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback: Stats Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsReporter(Callback):\n",
    "    '''Report training statistics in terms of the given metrics'''\n",
    "    \n",
    "    def __init__(self, metrics):\n",
    "        self.metrics = [] if metrics is None else metrics\n",
    "            \n",
    "    def before_epoch(self):\n",
    "        self.train_loss, self.valid_loss = 0., 0.\n",
    "        self.train_metrics = torch.tensor([0.]).expand(len(self.metrics))\n",
    "        self.valid_metrics = torch.tensor([0.]).expand(len(self.metrics))\n",
    "        self.train_count, self.valid_count = 0, 0\n",
    "    \n",
    "    def after_loss(self):\n",
    "        batch_len = self.control.xb.shape[0]\n",
    "        if self.control.in_train:\n",
    "            self.train_count += batch_len\n",
    "            self.train_loss += self.control.loss*batch_len\n",
    "            self.train_metrics += torch.tensor([m(self.control.pred,self.control.yb)*batch_len\\\n",
    "                                                for m in self.metrics])\n",
    "        else:\n",
    "            self.valid_count += batch_len\n",
    "            self.valid_loss += self.control.loss*batch_len\n",
    "            self.valid_metrics += torch.tensor([m(self.control.pred,self.control.yb)*batch_len\\\n",
    "                                                for m in self.metrics])\n",
    "\n",
    "        \n",
    "    def after_epoch(self):\n",
    "        header = f\"EPOCH#{self.control.epoch} \\t\"\n",
    "        train_avg_loss = self.train_loss / self.train_count\n",
    "        valid_avg_loss = self.valid_loss / self.valid_count\n",
    "        train_avg_metrics = self.train_metrics.numpy() / self.train_count\n",
    "        valid_avg_metrics = self.valid_metrics.numpy() / self.valid_count\n",
    "        train_str = f\"Train loss: {train_avg_loss:.3f} \\t metrics: {train_avg_metrics} \\t\"\n",
    "        valid_str = f\"Valid loss: {valid_avg_loss:.3f} \\t metrics: {valid_avg_metrics} \\t\"\n",
    "        print(header + train_str + valid_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = StatsReporter([utils.accuracy])\n",
    "control = Controller(callback_list=[reporter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Doesn't train. Fix it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH#0 \tTrain loss: 31200.246 \t metrics: [0.11316] \tValid loss: 2.302 \t metrics: [0.1064] \t\n",
      "EPOCH#1 \tTrain loss: 2.301 \t metrics: [0.11356] \tValid loss: 2.302 \t metrics: [0.1064] \t\n",
      "EPOCH#2 \tTrain loss: 2.301 \t metrics: [0.11356] \tValid loss: 2.302 \t metrics: [0.1064] \t\n",
      "EPOCH#3 \tTrain loss: 2.301 \t metrics: [0.11356] \tValid loss: 2.302 \t metrics: [0.1064] \t\n",
      "EPOCH#4 \tTrain loss: 2.301 \t metrics: [0.11356] \tValid loss: 2.302 \t metrics: [0.1064] \t\n",
      "EPOCH#5 \tTrain loss: 2.301 \t metrics: [0.11356] \tValid loss: 2.302 \t metrics: [0.1064] \t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b3e98456aab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ad2985a3f52e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, learner, epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_all_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_validate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ad2985a3f52e>\u001b[0m in \u001b[0;36mrun_all_batches\u001b[0;34m(self, dl)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_all_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "control.train(learner, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
